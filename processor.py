# -*- coding: utf-8 -*-
"""
å¤„ç†ä¸åŒè¾“å…¥ç±»å‹ï¼ˆURLã€æ–‡ä»¶ã€åˆ—è¡¨ï¼‰çš„å‡½æ•°æ¨¡å—ã€‚
åè°ƒå†…å®¹çš„è·å–ï¼ˆä¸‹è½½æˆ–è¯»å–ï¼‰ä¸ API æå–é€»è¾‘çš„è°ƒç”¨ã€‚
(ä¼˜åŒ–ç‰ˆæœ¬ v4.6 - ç²¾ç¡®æ§åˆ¶å½©è‰²æ‰“å°è¾“å‡º)
"""

import requests
import re
import logging
from urllib.parse import urljoin, urlparse, urlunparse
from requests.exceptions import RequestException, Timeout, HTTPError, ConnectionError
from pathlib import Path
from typing import Set, Optional, Generator, Union, List, Dict, Any

# --- é…ç½®æ—¥å¿— ---
log = logging.getLogger(__name__) # è·å–å½“å‰æ¨¡å—çš„æ—¥å¿—è®°å½•å™¨

# --- æ¨¡å—å¯¼å…¥ ---
try:
    # å¯¼å…¥æœ¬é¡¹ç›®å…¶ä»–æ¨¡å—
    import extractor # API æå–æ ¸å¿ƒé€»è¾‘
    import formatter # å‚æ•°æ ¼å¼åŒ–é€»è¾‘
    import utils     # å®ç”¨å·¥å…· (æ–‡ä»¶å†™å…¥, é¢œè‰²ç­‰)
    from utils import Colors # å¯¼å…¥é¢œè‰²ç±»ï¼Œç”¨äºæ§åˆ¶å°å½©è‰²è¾“å‡º
except ImportError as e:
    # å…³é”®ä¾èµ–ç¼ºå¤±ï¼Œè®°å½•ä¸¥é‡é”™è¯¯å¹¶é‡æ–°æŠ›å‡ºå¼‚å¸¸
    log.critical(f"æ— æ³•å¯¼å…¥ processor ä¾èµ–çš„æ¨¡å— (extractor, formatter, utils): {e}", exc_info=True)
    raise # æŠ›å‡ºå¼‚å¸¸ï¼Œç»ˆæ­¢ç¨‹åºè¿è¡Œ

# --- HTML è§£æåº“æ£€æŸ¥ ---
# å°è¯•å¯¼å…¥ BeautifulSoup4ï¼Œå¦‚æœå¯ç”¨åˆ™ä¼˜å…ˆä½¿ç”¨å®ƒè§£æ HTML
BS4_AVAILABLE = False
try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
    log.debug("BeautifulSoup4 å¯ç”¨ï¼Œå°†ç”¨äºè§£æ HTMLã€‚")
except ImportError:
    # å¦‚æœæœªå®‰è£… BS4ï¼Œåˆ™è®°å½•è­¦å‘Šï¼Œç¨‹åºå°†å›é€€åˆ°ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ HTML
    log.warning("BeautifulSoup4 æœªå®‰è£…ã€‚å°†ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ HTMLï¼Œè¿™å¯èƒ½ä¸å¤Ÿå¥å£®ã€‚å¼ºçƒˆå»ºè®®è¿è¡Œ 'pip install beautifulsoup4'ã€‚")

# --- å¸¸é‡å®šä¹‰ ---
DEFAULT_TIMEOUT = 30 # ç½‘ç»œè¯·æ±‚é»˜è®¤è¶…æ—¶æ—¶é—´ (ç§’)
# é»˜è®¤è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è¡Œä¸º
DEFAULT_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
    'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7', # æ·»åŠ ä¸­æ–‡è¯­è¨€åå¥½
    'Accept-Encoding': 'gzip, deflate, br', # è¯·æ±‚æ¥å—å‹ç¼©å†…å®¹
}

# --- æ­£åˆ™è¡¨è¾¾å¼ (ä¸»è¦ä½œä¸º BeautifulSoup çš„åå¤‡æˆ–è¡¥å……) ---
# åŒ¹é… <script> æ ‡ç­¾ä¸­çš„ src å±æ€§ (å¤–éƒ¨ JS æ–‡ä»¶)
SCRIPT_SRC_PATTERN = re.compile(
    r'<script[^>]+src\s*=\s*["\'](?P<src>[^"\']+\.js(?:\?[^"\']*)?)["\']', re.IGNORECASE
)
# åŒ¹é…å†…è” <script> æ ‡ç­¾çš„å†…å®¹ (ä¸å« src å±æ€§çš„ script æ ‡ç­¾)
INLINE_SCRIPT_PATTERN = re.compile(
    r'<script(?![^>]*\ssrc\s*=)(?:[^>]*)>(.*?)</script>', re.IGNORECASE | re.DOTALL
)

# --- è¾…åŠ©å‡½æ•° ---

def _is_valid_url(url: Optional[str]) -> bool:
    """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ HTTP æˆ– HTTPS URLã€‚"""
    if not isinstance(url, str): # ç¡®ä¿è¾“å…¥æ˜¯å­—ç¬¦ä¸²
        return False
    try:
        result = urlparse(url) # è§£æ URL
        # æ£€æŸ¥åè®®æ˜¯å¦ä¸º http æˆ– httpsï¼Œå¹¶ä¸”ç½‘ç»œä½ç½® (åŸŸå) å­˜åœ¨
        return all([result.scheme in ['http', 'https'], result.netloc])
    except ValueError:
        # è§£æå¤±è´¥ï¼Œå¯èƒ½ URL æ ¼å¼é”™è¯¯
        log.warning(f"è§£æ URL æ—¶å‡ºé”™ (å¯èƒ½æ— æ•ˆ): {url}")
        return False

def _normalize_url(base_url: str, link: Optional[str]) -> Optional[str]:
    """
    å°†ç›¸å¯¹ URL æˆ–åè®®ç›¸å¯¹ URL (//...) è§„èŒƒåŒ–ä¸ºç»å¯¹ URLã€‚
    Args:
        base_url: å½“å‰é¡µé¢çš„åŸºç¡€ URLã€‚
        link: ä»é¡µé¢ä¸­æå–çš„é“¾æ¥ (å¯èƒ½æ˜¯ç›¸å¯¹æˆ–ç»å¯¹çš„)ã€‚
    Returns:
        è§„èŒƒåŒ–åçš„ç»å¯¹ URL å­—ç¬¦ä¸²ï¼Œå¦‚æœæ— æ³•è§„èŒƒåŒ–æˆ–æ— æ•ˆåˆ™è¿”å› Noneã€‚
    """
    if not link or not isinstance(link, str): # æ£€æŸ¥ link æ˜¯å¦æœ‰æ•ˆ
        return None
    link = link.strip() # å»é™¤é¦–å°¾ç©ºç™½
    if not link:
        return None
    try:
        # urljoin ä¼šæ ¹æ® base_url è‡ªåŠ¨å¤„ç†ç›¸å¯¹è·¯å¾„ (å¦‚ /path, ../path, path) å’Œç»å¯¹è·¯å¾„
        joined_url = urljoin(base_url, link)
        # å†æ¬¡è§£æä»¥ç¡®ä¿ç»“æœæœ‰æ•ˆå¹¶è¿›è¡Œæ ‡å‡†åŒ–
        parsed_joined = urlparse(joined_url)
        if parsed_joined.scheme in ['http', 'https'] and parsed_joined.netloc:
            # ä½¿ç”¨ urlunparse é‡æ–°ç»„åˆ URLï¼Œç¡®ä¿æ ¼å¼æ ‡å‡†
            return urlunparse(parsed_joined)
        else:
            # å¦‚æœè§„èŒƒåŒ–åçš„ URL ä»ç„¶æ— æ•ˆ (ä¾‹å¦‚ï¼Œå˜æˆäº† file:// æˆ–ç¼ºå°‘åŸŸå)
            log.warning(f"è§„èŒƒåŒ–åçš„ URL æ— æ•ˆ: '{joined_url}' (åŸºå‡†: '{base_url}', é“¾æ¥: '{link}')")
            return None
    except Exception as e:
        # å¤„ç† urljoin æˆ– urlparse å¯èƒ½å‡ºç°çš„å¼‚å¸¸
        log.error(f"è§„èŒƒåŒ– URL '{link}' (åŸºå‡†: '{base_url}') æ—¶å‡ºé”™: {e}", exc_info=True)
        return None

def _fetch_content(url: str) -> Optional[str]:
    """
    ä¸‹è½½ç»™å®š URL çš„æ–‡æœ¬å†…å®¹ã€‚
    Args:
        url: è¦ä¸‹è½½çš„ URLã€‚
    Returns:
        ä¸‹è½½åˆ°çš„æ–‡æœ¬å†…å®¹å­—ç¬¦ä¸²ï¼Œå¦‚æœä¸‹è½½å¤±è´¥åˆ™è¿”å› Noneã€‚
    """
    log.debug(f"å°è¯•ä¸‹è½½ URL: {url}")
    try:
        # å‘é€ GET è¯·æ±‚
        response = requests.get(
            url,
            timeout=DEFAULT_TIMEOUT, # è®¾ç½®è¶…æ—¶
            headers=DEFAULT_HEADERS, # ä½¿ç”¨æ¨¡æ‹Ÿæµè§ˆå™¨çš„è¯·æ±‚å¤´
            verify=False, # è­¦å‘Š: ç¦ç”¨ SSL è¯ä¹¦éªŒè¯ (åœ¨å¤„ç†æŸäº› https ç«™ç‚¹æ—¶å¯èƒ½éœ€è¦ï¼Œä½†æœ‰å®‰å…¨é£é™©)
            stream=True # å»ºè®®ä½¿ç”¨ stream=Trueï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤§æ–‡ä»¶
        )
        response.raise_for_status() # æ£€æŸ¥ HTTP é”™è¯¯çŠ¶æ€ç  (ä¾‹å¦‚ 404, 500)
        # ç¡®å®šå“åº”å†…å®¹çš„ç¼–ç ã€‚ä¼˜å…ˆä½¿ç”¨å“åº”å¤´æŒ‡å®šçš„ç¼–ç ï¼Œå…¶æ¬¡æ˜¯ requests æ¨æµ‹çš„ç¼–ç ï¼Œæœ€åé»˜è®¤ utf-8
        response.encoding = response.encoding or response.apparent_encoding or 'utf-8'
        content = response.text # è·å–è§£ç åçš„æ–‡æœ¬å†…å®¹
        log.debug(f"æˆåŠŸä¸‹è½½ URL: {url} (å†…å®¹é•¿åº¦: {len(content)})")
        return content
    except Timeout:
        log.error(f"è¯·æ±‚ URL è¶…æ—¶ {url} (è¶…æ—¶: {DEFAULT_TIMEOUT}s)")
        # æ¢å¤ä¸‹è½½å¤±è´¥æ‰“å°åˆ° stderr
        print(f"  {Colors.FAIL}âŒ ä¸‹è½½æˆ–å¤„ç† URL è¶…æ—¶: {url}{Colors.RESET}", file=sys.stderr)
    except HTTPError as e:
        log.error(f"è¯·æ±‚ URL å¤±è´¥ {url} (HTTPçŠ¶æ€ç : {e.response.status_code})")
        # æ¢å¤ä¸‹è½½å¤±è´¥æ‰“å°åˆ° stderr
        print(f"  {Colors.FAIL}âŒ è¯·æ±‚ URL å¤±è´¥ ({e.response.status_code}): {url}{Colors.RESET}", file=sys.stderr)
    except ConnectionError as e:
        log.error(f"è¯·æ±‚ URL è¿æ¥é”™è¯¯ {url}: {e}")
        # æ¢å¤ä¸‹è½½å¤±è´¥æ‰“å°åˆ° stderr
        print(f"  {Colors.FAIL}âŒ è¯·æ±‚ URL è¿æ¥é”™è¯¯: {url} - {e}{Colors.RESET}", file=sys.stderr)
    except RequestException as e:
        # æ•è· requests åº“çš„å…¶ä»–ç½‘ç»œç›¸å…³å¼‚å¸¸
        log.error(f"è¯·æ±‚ URL æ—¶å‘ç”Ÿå…¶ä»–ç½‘ç»œé”™è¯¯ {url}: {e}")
        # æ¢å¤ä¸‹è½½å¤±è´¥æ‰“å°åˆ° stderr
        print(f"  {Colors.FAIL}âŒ è¯·æ±‚ URL æ—¶å‘ç”Ÿç½‘ç»œé”™è¯¯: {url} - {e}{Colors.RESET}", file=sys.stderr)
    except Exception as e:
        # æ•è·å…¶ä»–æ„å¤–é”™è¯¯
        log.error(f"ä¸‹è½½ URL {url} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}", exc_info=True)
        # æ¢å¤ä¸‹è½½å¤±è´¥æ‰“å°åˆ° stderr
        print(f"  {Colors.FAIL}âŒ ä¸‹è½½ URL æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {url} - {e}{Colors.RESET}", file=sys.stderr)
    return None # ä¸‹è½½å¤±è´¥è¿”å› None

# --- æ ¸å¿ƒå¤„ç†å‡½æ•° ---

def process_js_content(js_content: str, source_name: str, output_file_path: Union[str, Path]) -> int:
    """
    å¤„ç†å•æ®µ JavaScript æºä»£ç ï¼šæå– API è¯·æ±‚ï¼Œå¹¶å°†è¯¦ç»†ç»“æœå†™å…¥æ–‡ä»¶ã€‚
    ä¿ç•™å½©è‰²æ‘˜è¦æ‰“å°åˆ°æ§åˆ¶å°ã€‚

    Args:
        js_content: JavaScript æºä»£ç å­—ç¬¦ä¸²ã€‚
        source_name: å†…å®¹æ¥æºæ ‡è¯† (URL æˆ–æ–‡ä»¶å)ã€‚
        output_file_path: ç»“æœè¾“å‡ºæ–‡ä»¶çš„è·¯å¾„ (å­—ç¬¦ä¸²æˆ– Path å¯¹è±¡)ã€‚

    Returns:
        æå–åˆ°çš„è¯·æ±‚æ•°é‡ã€‚
    """
    output_lines_for_file = [f"\n--- æ¥æº: {source_name} ---", "=" * 60] # æ–‡ä»¶è¾“å‡ºå†…å®¹çš„åˆ—è¡¨
    extracted_count = 0 # æå–åˆ°çš„æ€»è¯·æ±‚æ•°
    param_count = 0     # å¸¦å‚æ•°çš„è¯·æ±‚æ•°

    try:
        # è°ƒç”¨ extractor æ¨¡å—è¿›è¡Œ API æå–
        results: List[Dict[str, Any]] = extractor.extract_requests(js_content)
        extracted_count = len(results)

        if results:
            log.info(f"åœ¨ {source_name} ä¸­æ‰¾åˆ° {extracted_count} ä¸ªæ½œåœ¨è¯·æ±‚ã€‚")
            for result in results:
                # --- å‡†å¤‡æ–‡ä»¶è¾“å‡ºå†…å®¹ ---
                # å†™å…¥ç±»å‹ã€æ–¹æ³•å’Œ URL
                output_lines_for_file.append(f"ç±»å‹: {result['type']}, è¯·æ±‚: \"{result['method']} {result['url']}\"")
                # è°ƒç”¨ formatter æ ¼å¼åŒ–å‚æ•°
                formatted_params = formatter.format_params(result.get('params'))
                output_lines_for_file.append(f"è¯·æ±‚å‚æ•°: {formatted_params}")
                output_lines_for_file.append("-" * 60) # æ·»åŠ åˆ†éš”ç¬¦

                # --- ç»Ÿè®¡å¸¦å‚æ•°çš„è¯·æ±‚ ---
                # æ£€æŸ¥åŸå§‹å‚æ•°æ˜¯å¦å­˜åœ¨ä¸”æ ¼å¼åŒ–åä¸æ˜¯ "æ— å‚æ•°"
                if result.get('params') and formatted_params != "æ— å‚æ•°":
                    param_count += 1

            # --- æ‰“å°å½©è‰²æ‘˜è¦åˆ°æ§åˆ¶å° ---
            # æ¢å¤å½©è‰²æ‘˜è¦æ‰“å°ï¼Œä¿®æ”¹æ ¼å¼ä»¥åŒ¹é…ç¤ºä¾‹
            print(f"\tğŸ‘ï¸{Colors.INFO}ä» {Colors.SOURCE}{source_name}{Colors.RESET}{Colors.INFO} å‘ç° {Colors.COUNT}{extracted_count}{Colors.RESET}{Colors.INFO} ä¸ªæ¥å£ ({Colors.PARAM_COUNT}{param_count}{Colors.RESET}{Colors.INFO} ä¸ªå¸¦å‚æ•°){Colors.RESET}")

        else:
            # æœªæ‰¾åˆ°è¯·æ±‚
            output_lines_for_file.append("æœªæ‰¾åˆ°è¯·æ±‚ä¿¡æ¯")
            log.info(f"åœ¨ {source_name} ä¸­æœªæ‰¾åˆ°è¯·æ±‚ä¿¡æ¯ã€‚")
            # æ¢å¤æœªæ‰¾åˆ°çš„æ‘˜è¦æ‰“å°ï¼Œä¿®æ”¹æ ¼å¼ä»¥åŒ¹é…ç¤ºä¾‹
            print(f"\tğŸ‘ï¸{Colors.INFO}ä» {Colors.SOURCE}{source_name}{Colors.RESET}{Colors.INFO} å‘ç° {Colors.COUNT}0{Colors.RESET}{Colors.INFO} ä¸ªæ¥å£ (0 ä¸ªå¸¦å‚æ•°){Colors.RESET}")

    except Exception as e:
        # å¤„ç† JS å†…å®¹åˆ†æè¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„å¼‚å¸¸
        error_msg = f"é”™è¯¯ï¼šå¤„ç† JS å†…å®¹æ—¶å‡ºé”™ ({source_name}): {e}"
        output_lines_for_file.append(error_msg) # è®°å½•åˆ°æ–‡ä»¶
        log.error(error_msg, exc_info=True)     # è®°å½•åˆ°æ—¥å¿—
        # æ¢å¤é”™è¯¯æ‰“å°åˆ°æ§åˆ¶å°
        print(f"\t{Colors.FAIL}âŒ å¤„ç† JS å†…å®¹æ—¶å‡ºé”™ ({Colors.SOURCE}{source_name}{Colors.RESET}{Colors.FAIL}): {e}{Colors.RESET}", file=sys.stderr)

    # å°†è¯¦ç»†ç»“æœå†™å…¥æ–‡ä»¶
    utils.write_to_file(output_file_path, "\n".join(output_lines_for_file) + "\n\n")

    return extracted_count

def process_js_url(url: str, output_file_path: Union[str, Path], processed_urls_cache: Set[str]) -> None:
    """
    å¤„ç†å•ä¸ª JavaScript URLï¼šä¸‹è½½å†…å®¹å¹¶è¿›è¡Œåˆ†æã€‚
    ä¿ç•™æ‰“å°ä¿¡æ¯ã€‚

    Args:
        url: JS æ–‡ä»¶ URLã€‚
        output_file_path: ç»“æœè¾“å‡ºæ–‡ä»¶çš„è·¯å¾„ (å­—ç¬¦ä¸²æˆ– Path å¯¹è±¡)ã€‚
        processed_urls_cache: å·²å¤„ç† URL çš„ç¼“å­˜é›†åˆ (é¿å…é‡å¤å¤„ç†)ã€‚
    """
    log.info(f"å‡†å¤‡å¤„ç† JS URL: {url}")
    # æ¢å¤å¼€å§‹åˆ†æçš„æ¶ˆæ¯æ‰“å°ï¼Œä¿®æ”¹æ ¼å¼ä»¥åŒ¹é…ç¤ºä¾‹
    print(f"ğŸ”{Colors.INFO}å¼€å§‹åˆ†æ JS URL: {Colors.PATH}{url}{Colors.RESET}")

    # éªŒè¯ URL æ ¼å¼
    if not _is_valid_url(url):
        error_msg = f"é”™è¯¯ï¼šæä¾›çš„ JS URL æ— æ•ˆæˆ–ä¸æ”¯æŒ: {url}"
        log.error(error_msg)
        # æ¢å¤æ— æ•ˆ URL æ‰“å°åˆ° stderr
        print(f"\t{Colors.FAIL}âŒ æ— æ•ˆ JS URL: {url}{Colors.RESET}", file=sys.stderr)
        utils.write_to_file(output_file_path, error_msg + "\n\n")
        return

    # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡æ­¤ URL
    if url in processed_urls_cache:
        log.info(f"è·³è¿‡å·²å¤„ç†çš„ JS URL: {url}")
        # æ¢å¤è·³è¿‡æ‰“å°
        print(f"\t{Colors.WARNING}âš ï¸ è·³è¿‡å·²å¤„ç†çš„ JS URL: {url}{Colors.RESET}")
        return

    # å°†å½“å‰ URL æ·»åŠ åˆ°ç¼“å­˜
    processed_urls_cache.add(url)
    # ä¸‹è½½ JS å†…å®¹
    js_content = _fetch_content(url)

    if js_content is not None: # æ£€æŸ¥æ˜¯å¦ä¸‹è½½æˆåŠŸ
        # (å¯é€‰) æ£€æŸ¥ Content-Typeï¼Œå¢åŠ è­¦å‘Šä¿¡æ¯
        try:
            response = requests.head(url, timeout=5, headers=DEFAULT_HEADERS, verify=False)
            content_type = response.headers.get('content-type', '').lower()
            if 'javascript' not in content_type and 'text/plain' not in content_type:
                log.warning(f"URL {url} çš„ Content-Type ('{content_type}') å¯èƒ½ä¸æ˜¯ JSï¼Œä½†ä»å°†å¤„ç†ã€‚")
        except Exception as head_err:
            log.debug(f"æ— æ³•è·å– URL {url} çš„ HEAD ä¿¡æ¯: {head_err}")

        # å¦‚æœå†…å®¹éç©ºï¼Œåˆ™è¿›è¡Œå¤„ç†
        if js_content:
             process_js_content(js_content, url, output_file_path)
        else:
             # å†…å®¹ä¸ºç©º
             log.warning(f"URL è¿”å›ç©ºå†…å®¹: {url}")
             # æ¢å¤ç©ºå†…å®¹è­¦å‘Šæ‰“å°
             print(f"\t{Colors.WARNING}âš ï¸ URL è¿”å›ç©ºå†…å®¹: {url}{Colors.RESET}")
             utils.write_to_file(output_file_path, f"è­¦å‘Šï¼šURL è¿”å›ç©ºå†…å®¹: {url}\n\n")
    # else: ä¸‹è½½å¤±è´¥çš„é”™è¯¯å·²ç»åœ¨ _fetch_content ä¸­å¤„ç†å¹¶æ‰“å°


def process_js_file(file_path_str: str, output_file_path: Union[str, Path]) -> None:
    """
    å¤„ç†å•ä¸ªæœ¬åœ° JavaScript æ–‡ä»¶ã€‚
    ä¿ç•™æ‰“å°ä¿¡æ¯ã€‚

    Args:
        file_path_str: æœ¬åœ° JS æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²ã€‚
        output_file_path: ç»“æœè¾“å‡ºæ–‡ä»¶çš„è·¯å¾„ (å­—ç¬¦ä¸²æˆ– Path å¯¹è±¡)ã€‚
    """
    file_path = Path(file_path_str) # è½¬æ¢ä¸º Path å¯¹è±¡
    log.info(f"å‡†å¤‡å¤„ç†æœ¬åœ° JS æ–‡ä»¶: {file_path}")
    # æ¢å¤å¼€å§‹åˆ†æçš„æ¶ˆæ¯æ‰“å°ï¼Œä¿®æ”¹æ ¼å¼ä»¥åŒ¹é…ç¤ºä¾‹
    print(f"ğŸ”{Colors.INFO}å¼€å§‹åˆ†ææœ¬åœ°æ–‡ä»¶: {Colors.PATH}{file_path}{Colors.RESET}")

    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æ˜¯æ–‡ä»¶ç±»å‹
        if not file_path.is_file():
             raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆæ–‡ä»¶: {file_path}")
        # è¯»å–æ–‡ä»¶å†…å®¹ï¼ŒæŒ‡å®š utf-8 ç¼–ç ï¼Œå¿½ç•¥æ— æ³•è§£ç çš„å­—ç¬¦
        js_content = file_path.read_text(encoding='utf-8', errors='ignore')
        # å¦‚æœå†…å®¹éç©ºï¼Œåˆ™è¿›è¡Œå¤„ç†
        if js_content:
            process_js_content(js_content, str(file_path), output_file_path)
        else:
             # æ–‡ä»¶ä¸ºç©º
             log.warning(f"æ–‡ä»¶ä¸ºç©º: {file_path}")
             # æ¢å¤æ–‡ä»¶ä¸ºç©ºè­¦å‘Šæ‰“å°
             print(f"\t{Colors.WARNING}âš ï¸ æ–‡ä»¶ä¸ºç©º: {file_path}{Colors.RESET}")
             utils.write_to_file(output_file_path, f"è­¦å‘Šï¼šæ–‡ä»¶ä¸ºç©º: {file_path}\n\n")
    except FileNotFoundError as e:
        error_msg = f"é”™è¯¯ï¼šæœ¬åœ° JS æ–‡ä»¶æœªæ‰¾åˆ°: {e}"
        log.error(error_msg)
        # æ¢å¤æ–‡ä»¶æœªæ‰¾åˆ°æ‰“å°åˆ° stderr
        print(f"\t{Colors.FAIL}âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}{Colors.RESET}", file=sys.stderr)
        utils.write_to_file(output_file_path, error_msg + "\n\n")
    except IOError as e:
        error_msg = f"é”™è¯¯ï¼šè¯»å–æœ¬åœ° JS æ–‡ä»¶æ—¶å‡ºé”™ {file_path}: {e}"
        log.error(error_msg)
        # æ¢å¤è¯»å–æ–‡ä»¶é”™è¯¯æ‰“å°åˆ° stderr
        print(f"\t{Colors.FAIL}âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {file_path} - {e}{Colors.RESET}", file=sys.stderr)
        utils.write_to_file(output_file_path, error_msg + "\n\n")
    except Exception as e:
        error_msg = f"é”™è¯¯ï¼šå¤„ç†æœ¬åœ° JS æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}"
        log.error(error_msg, exc_info=True)
        # æ¢å¤å¤„ç†æ–‡ä»¶æ„å¤–é”™è¯¯æ‰“å°åˆ° stderr
        print(f"\t{Colors.FAIL}âŒ å¤„ç†æ–‡ä»¶æ—¶æ„å¤–å‡ºé”™: {file_path} - {e}{Colors.RESET}", file=sys.stderr)
        utils.write_to_file(output_file_path, error_msg + "\n\n")

def _extract_js_from_html(html_content: str, base_url: str, output_file_path: Union[str, Path], processed_js_urls_cache: Set[str]) -> bool:
    """
    ä» HTML å†…å®¹ä¸­æå–å¤–éƒ¨å’Œå†…è” JS å¹¶è¿›è¡Œå¤„ç†ã€‚
    ç§»é™¤æ‰“å°ä¿¡æ¯ã€‚

    Args:
        html_content: HTML æºä»£ç å­—ç¬¦ä¸²ã€‚
        base_url: HTML é¡µé¢çš„åŸºç¡€ URLï¼Œç”¨äºè§„èŒƒåŒ–ç›¸å¯¹è·¯å¾„ã€‚
        output_file_path: ç»“æœè¾“å‡ºæ–‡ä»¶çš„è·¯å¾„ã€‚
        processed_js_urls_cache: å·²å¤„ç† JS URL çš„ç¼“å­˜ã€‚

    Returns:
        å¦‚æœæ‰¾åˆ°äº†ä»»ä½• JS (å¤–éƒ¨æˆ–å†…è”)ï¼Œåˆ™è¿”å› Trueï¼Œå¦åˆ™è¿”å› Falseã€‚
    """
    js_found = False # æ ‡è®°æ˜¯å¦æ‰¾åˆ° JS
    total_js_links = 0 # æ‰¾åˆ°çš„å¤–éƒ¨ JS é“¾æ¥æ€»æ•°

    # --- ä¼˜å…ˆä½¿ç”¨ BeautifulSoup (å¦‚æœå¯ç”¨) ---
    if BS4_AVAILABLE:
        try:
            log.debug(f"ä½¿ç”¨ BeautifulSoup è§£æ HTML (æ¥æº: {base_url})")
            soup = BeautifulSoup(html_content, 'html.parser') # ä½¿ç”¨ html.parser

            # --- æå–å¤–éƒ¨ JS ---
            script_tags = soup.find_all('script', src=True) # æŸ¥æ‰¾æ‰€æœ‰å¸¦ src å±æ€§çš„ script æ ‡ç­¾
            total_js_links = len(script_tags)
            log.info(f"åœ¨ {base_url} ä¸­æ‰¾åˆ° {total_js_links} ä¸ªå¤–éƒ¨ JS é“¾æ¥ (BS4)ã€‚")
            # ç§»é™¤æ‰¾åˆ°å¤–éƒ¨ JS æ•°é‡çš„æ‰“å° (ä¸ç¬¦åˆç¤ºä¾‹æ ¼å¼)
            # if total_js_links > 0:
            #      print(f"  å‘ç° {Colors.COUNT}{total_js_links}{Colors.RESET} ä¸ªå¤–éƒ¨ JS æ–‡ä»¶é“¾æ¥ã€‚")

            # éå†æ‰¾åˆ°çš„ script æ ‡ç­¾
            for tag in script_tags:
                js_src = tag.get('src') # è·å– src å±æ€§å€¼
                if js_src:
                    # è§„èŒƒåŒ– URL
                    full_js_url = _normalize_url(base_url, js_src)
                    if full_js_url:
                        js_found = True # æ ‡è®°æ‰¾åˆ° JS
                        # å¤„ç†è¿™ä¸ª JS URL (ä¸‹è½½å’Œåˆ†æ)
                        # process_js_url å‡½æ•°å†…éƒ¨çš„æ‰“å°ä¹Ÿå·²ç»è¢«ç§»é™¤
                        # æ³¨æ„ï¼šè¿™é‡Œä¸æ‰“å° "å¼€å§‹åˆ†æ JS URL"ï¼Œå› ä¸ºè¿™æ˜¯ä» HTML ä¸­æå–çš„å­ä»»åŠ¡
                        # æå–ç»“æœæ‘˜è¦ä¼šåœ¨ process_js_content ä¸­æ‰“å°
                        if full_js_url not in processed_js_urls_cache:
                             # ä»…åœ¨æœªå¤„ç†è¿‡æ—¶æ‰“å°ç®€ç•¥ä¿¡æ¯å¹¶å¤„ç†
                             log.info(f"  æå–åˆ°å¤–éƒ¨ JS: {full_js_url}")
                             process_js_url(full_js_url, output_file_path, processed_js_urls_cache)
                        else:
                             log.info(f"  è·³è¿‡å·²å¤„ç†çš„å¤–éƒ¨ JS: {full_js_url}")


                    else:
                        # è®°å½•æ— æ³•å¤„ç†çš„é“¾æ¥
                        log.info(f"è·³è¿‡æ— æ•ˆæˆ–æ— æ³•è§„èŒƒåŒ–çš„ JS é“¾æ¥: {js_src} (æ¥è‡ª: {base_url})")
                        # ç§»é™¤æ— æ•ˆé“¾æ¥æ‰“å° (ä¸ç¬¦åˆç¤ºä¾‹æ ¼å¼)
                        # print(f"  {Colors.WARNING}âš ï¸ è·³è¿‡æ— æ•ˆæˆ–æ— æ³•è§„èŒƒåŒ–çš„ JS é“¾æ¥: {js_src}{Colors.RESET}")


            # --- æå–å†…è” JS ---
            # æŸ¥æ‰¾æ‰€æœ‰ä¸å¸¦ src å±æ€§ä¸”å†…å®¹ä¸ä¸ºç©ºçš„ script æ ‡ç­¾
            inline_scripts = [tag.string for tag in soup.find_all('script', src=False) if tag.string and tag.string.strip()]
            if inline_scripts:
                js_found = True # æ ‡è®°æ‰¾åˆ° JS
                log.info(f"åœ¨ {base_url} ä¸­æ‰¾åˆ° {len(inline_scripts)} ä¸ªå†…è” JS å— (BS4)ã€‚")
                # ç§»é™¤æ‰¾åˆ°å†…è” JS æ•°é‡çš„æ‰“å° (ä¸ç¬¦åˆç¤ºä¾‹æ ¼å¼)
                # print(f"  {Colors.INFO}å‘ç° {Colors.COUNT}{len(inline_scripts)}{Colors.RESET}{Colors.INFO} ä¸ªå†…è” JS å—ã€‚{Colors.RESET}")
                # å†™å…¥æ–‡ä»¶åˆ†éš”ç¬¦
                utils.write_to_file(output_file_path, "\n--- åˆ†æå†…è” JavaScript ---\n")
                # åˆå¹¶æ‰€æœ‰å†…è”è„šæœ¬è¿›è¡Œä¸€æ¬¡æ€§å¤„ç†ï¼Œæé«˜æ•ˆç‡
                combined_inline = "\n\n; // Inline Script Separator \n\n".join(inline_scripts)
                # å¤„ç†åˆå¹¶åçš„å†…è”è„šæœ¬å†…å®¹
                # process_js_content å‡½æ•°å†…éƒ¨çš„æ‰“å°ä¹Ÿå·²ç»è¢«ç§»é™¤
                process_js_content(combined_inline, f"{base_url} (å†…è”è„šæœ¬)", output_file_path)
            else:
                log.info(f"åœ¨ {base_url} ä¸­æœªæ‰¾åˆ°å†…è” JS (BS4)ã€‚")
                # ç§»é™¤æœªæ‰¾åˆ°å†…è” JS æ‰“å° (ä¸ç¬¦åˆç¤ºä¾‹æ ¼å¼)
                # print(f"  {Colors.WARNING}âš ï¸ åœ¨ {base_url} ä¸­æœªæ‰¾åˆ°å†…è” JSã€‚{Colors.RESET}")


        except Exception as bs_err:
            # å¤„ç† BeautifulSoup è§£ææ—¶å¯èƒ½å‘ç”Ÿçš„é”™è¯¯
            log.error(f"ä½¿ç”¨ BeautifulSoup è§£æ HTML æ—¶å‡ºé”™ ({base_url}): {bs_err}", exc_info=True)
            # æ¢å¤ HTML è§£æå¤±è´¥æ‰“å°åˆ° stderr
            print(f"  {Colors.FAIL}âŒ HTML è§£æå¤±è´¥ (BeautifulSoup): {base_url} - {bs_err}{Colors.RESET}", file=sys.stderr)
            utils.write_to_file(output_file_path, f"é”™è¯¯ï¼šHTML è§£æå¤±è´¥ ({base_url}): {bs_err}\n\n")
            return False # è§£æå¤±è´¥

    # --- ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ (å¦‚æœ BS4 ä¸å¯ç”¨) ---
    else:
        log.debug(f"ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ HTML (æ¥æº: {base_url})")
        # --- æå–å¤–éƒ¨ JS (æ­£åˆ™) ---
        js_links_found = []
        try:
            for match in SCRIPT_SRC_PATTERN.finditer(html_content):
                js_src = match.group('src')
                if js_src:
                    full_js_url = _normalize_url(base_url, js_src)
                    if full_js_url:
                        js_links_found.append(full_js_url)
                    else:
                        log.info(f"è·³è¿‡æ— æ•ˆæˆ–æ— æ³•è§„èŒƒåŒ–çš„ JS é“¾æ¥: {js_src} (æ¥è‡ª: {base_url})")
            total_js_links = len(js_links_found)
            log.info(f"åœ¨ {base_url} ä¸­æ‰¾åˆ° {total_js_links} ä¸ªå¤–éƒ¨ JS é“¾æ¥ (æ­£åˆ™)ã€‚")
            # ç§»é™¤æ‰¾åˆ°å¤–éƒ¨ JS æ•°é‡çš„æ‰“å° (ä¸ç¬¦åˆç¤ºä¾‹æ ¼å¼)
            # if total_js_links > 0:
            #      print(f"  å‘ç° {Colors.COUNT}{total_js_links}{Colors.RESET} ä¸ªå¤–éƒ¨ JS æ–‡ä»¶é“¾æ¥ã€‚")

            # å¤„ç†æ‰¾åˆ°çš„ JS é“¾æ¥
            for full_js_url in js_links_found:
                 js_found = True
                 # process_js_url å‡½æ•°å†…éƒ¨çš„æ‰“å°ä¹Ÿå·²ç»è¢«ç§»é™¤
                 # æ³¨æ„ï¼šè¿™é‡Œä¸æ‰“å° "å¼€å§‹åˆ†æ JS URL"
                 if full_js_url not in processed_js_urls_cache:
                     log.info(f"  æå–åˆ°å¤–éƒ¨ JS: {full_js_url}")
                     process_js_url(full_js_url, output_file_path, processed_js_urls_cache)
                 else:
                     log.info(f"  è·³è¿‡å·²å¤„ç†çš„å¤–éƒ¨ JS: {full_js_url}")


        except Exception as regex_err:
             log.error(f"ä½¿ç”¨æ­£åˆ™æå–å¤–éƒ¨ JS æ—¶å‡ºé”™ ({base_url}): {regex_err}", exc_info=True)
             # æ¢å¤é”™è¯¯æ‰“å°åˆ° stderr
             print(f"  {Colors.FAIL}âŒ ä½¿ç”¨æ­£åˆ™æå–å¤–éƒ¨ JS æ—¶å‡ºé”™: {base_url} - {regex_err}{Colors.RESET}", file=sys.stderr)


        # --- æå–å†…è” JS (æ­£åˆ™) ---
        inline_scripts = []
        try:
            for match in INLINE_SCRIPT_PATTERN.finditer(html_content):
                script_content = match.group(1)
                if script_content and script_content.strip():
                    inline_scripts.append(script_content.strip())
            if inline_scripts:
                js_found = True
                log.info(f"åœ¨ {base_url} ä¸­æ‰¾åˆ° {len(inline_scripts)} ä¸ªå†…è” JS å— (æ­£åˆ™)ã€‚")
                # ç§»é™¤æ‰¾åˆ°å†…è” JS æ•°é‡çš„æ‰“å° (ä¸ç¬¦åˆç¤ºä¾‹æ ¼å¼)
                # print(f"  {Colors.INFO}å‘ç° {Colors.COUNT}{len(inline_scripts)}{Colors.RESET}{Colors.INFO} ä¸ªå†…è” JS å—ã€‚{Colors.RESET}")
                utils.write_to_file(output_file_path, "\n--- åˆ†æå†…è” JavaScript ---\n")
                combined_inline = "\n\n; // Inline Script Separator \n\n".join(inline_scripts)
                # process_js_content å‡½æ•°å†…éƒ¨çš„æ‰“å°ä¹Ÿå·²ç»è¢«ç§»é™¤
                process_js_content(combined_inline, f"{base_url} (å†…è”è„šæœ¬)", output_file_path)
            else:
                log.info(f"åœ¨ {base_url} ä¸­æœªæ‰¾åˆ°å†…è” JS (æ­£åˆ™)ã€‚")
                # ç§»é™¤æœªæ‰¾åˆ°å†…è” JS æ‰“å° (ä¸ç¬¦åˆç¤ºä¾‹æ ¼å¼)
                # print(f"  {Colors.WARNING}âš ï¸ åœ¨ {base_url} ä¸­æœªæ‰¾åˆ°å†…è” JSã€‚{Colors.RESET}")

        except Exception as regex_err:
             log.error(f"ä½¿ç”¨æ­£åˆ™æå–å†…è” JS æ—¶å‡ºé”™ ({base_url}): {regex_err}", exc_info=True)
             # æ¢å¤é”™è¯¯æ‰“å°åˆ° stderr
             print(f"  {Colors.FAIL}âŒ ä½¿ç”¨æ­£åˆ™æå–å†…è” JS æ—¶å‡ºé”™: {base_url} - {regex_err}{Colors.RESET}", file=sys.stderr)


    # å¦‚æœæ•´ä¸ªé¡µé¢æ—¢æ²¡æœ‰å¤–éƒ¨ JS ä¹Ÿæ²¡æœ‰å†…è” JS
    if not js_found:
        parser_method = "BeautifulSoup" if BS4_AVAILABLE else "æ­£åˆ™åŒ¹é…"
        no_js_msg = f"ä¿¡æ¯ï¼šé¡µé¢ä¸­æœªæ‰¾åˆ°å¤–éƒ¨æˆ–å†…è” JavaScript (ä½¿ç”¨ {parser_method})ã€‚"
        log.info(no_js_msg)
        # æ¢å¤æœªæ‰¾åˆ° JS è­¦å‘Šæ‰“å°
        print(f"  {Colors.WARNING}âš ï¸ é¡µé¢ä¸­æœªæ‰¾åˆ° JS: {base_url}{Colors.RESET}")
        utils.write_to_file(output_file_path, no_js_msg + "\n\n")

    return js_found


def read_urls_from_file(file_path: Path) -> Generator[str, None, None]:
    """
    ä»æ–‡ä»¶ä¸­é€è¡Œè¯»å–æœ‰æ•ˆçš„ URL (å¿½ç•¥ç©ºè¡Œå’Œ # æ³¨é‡Šè¡Œ)ã€‚
    ä½¿ç”¨ç”Ÿæˆå™¨ä»¥èŠ‚çœå†…å­˜ã€‚
    """
    try:
        # ä½¿ç”¨ utf-8 ç¼–ç æ‰“å¼€æ–‡ä»¶ï¼Œå¿½ç•¥è§£ç é”™è¯¯
        with file_path.open('r', encoding='utf-8', errors='ignore') as f:
            for line_num, line in enumerate(f, 1):
                url = line.strip() # å»é™¤é¦–å°¾ç©ºç™½
                if url and not url.startswith('#'): # å¦‚æœè¡Œå†…å®¹éç©ºä¸”ä¸æ˜¯æ³¨é‡Š
                    yield url # äº§ç”Ÿ URL
                elif url.startswith('#'):
                    log.debug(f"è·³è¿‡æ³¨é‡Šè¡Œ {line_num}: {url}")
                # ç©ºè¡Œä¼šè¢«è‡ªåŠ¨å¿½ç•¥ (å› ä¸º url ä¸º False)
    except FileNotFoundError:
        log.error(f"URL åˆ—è¡¨æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        # æ¢å¤æ–‡ä»¶æœªæ‰¾åˆ°æ‰“å°åˆ° stderr
        print(f"{Colors.FAIL}âŒ URL åˆ—è¡¨æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}{Colors.RESET}", file=sys.stderr)
        raise # é‡æ–°æŠ›å‡ºï¼Œè®©ä¸Šå±‚å¤„ç†
    except IOError as e:
        log.error(f"è¯»å– URL åˆ—è¡¨æ–‡ä»¶æ—¶å‡ºé”™ {file_path}: {e}")
        # æ¢å¤è¯»å–æ–‡ä»¶é”™è¯¯æ‰“å°åˆ° stderr
        print(f"{Colors.FAIL}âŒ è¯»å– URL åˆ—è¡¨æ–‡ä»¶æ—¶å‡ºé”™: {file_path} - {e}{Colors.RESET}", file=sys.stderr)
        raise # é‡æ–°æŠ›å‡º
    except Exception as e:
        error_msg = f"è¯»å– URL åˆ—è¡¨æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}"
        log.error(error_msg, exc_info=True)
        # æ¢å¤å¤„ç†æ–‡ä»¶æ„å¤–é”™è¯¯æ‰“å°åˆ° stderr
        print(f"{Colors.FAIL}âŒ è¯»å– URL åˆ—è¡¨æ–‡ä»¶æ—¶æ„å¤–å‡ºé”™: {file_path} - {e}{Colors.RESET}", file=sys.stderr)
        raise

def process_url_list_file(file_path_str: str, is_js_list: bool, output_file: Union[str, Path]) -> None:
    """
    å¤„ç†åŒ…å« URL åˆ—è¡¨çš„æ–‡ä»¶ï¼ˆç½‘é¡µ URL æˆ– JS URLï¼‰ã€‚
    ä¿ç•™æ‰“å°ä¿¡æ¯ã€‚

    Args:
        file_path_str: URL åˆ—è¡¨æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²ã€‚
        is_js_list: True è¡¨ç¤ºæ–‡ä»¶å†…å®¹æ˜¯ JS URL åˆ—è¡¨, False è¡¨ç¤ºæ˜¯ç½‘é¡µ URL åˆ—è¡¨ã€‚
        output_file: ç»“æœè¾“å‡ºæ–‡ä»¶çš„è·¯å¾„ (å­—ç¬¦ä¸²æˆ– Path å¯¹è±¡)ã€‚
    """
    file_path = Path(file_path_str) # è½¬æ¢ä¸º Path å¯¹è±¡
    list_type = "JavaScript URL" if is_js_list else "ç½‘é¡µ URL" # ç¡®å®šåˆ—è¡¨ç±»å‹æè¿°
    log.info(f"å‡†å¤‡å¤„ç† {list_type} åˆ—è¡¨æ–‡ä»¶: {file_path}")
    # æ¢å¤å¼€å§‹å¤„ç†åˆ—è¡¨æ–‡ä»¶çš„æ¶ˆæ¯æ‰“å°ï¼Œä¿®æ”¹æ ¼å¼ä»¥åŒ¹é…ç¤ºä¾‹
    print(f"ğŸ”{Colors.INFO}å¼€å§‹åˆ†æåˆ—è¡¨æ–‡ä»¶: {Colors.PATH}{file_path}{Colors.RESET}")
    # å†™å…¥æ–‡ä»¶åˆ†éš”ç¬¦
    utils.write_to_file(output_file, f"## åˆ†æ {list_type} åˆ—è¡¨æ–‡ä»¶: {file_path}\n" + "="*60 + "\n")

    processed_count = 0 # æˆåŠŸå¤„ç†çš„ URL æ•°é‡
    error_count = 0     # å¤„ç†å¤±è´¥çš„ URL æ•°é‡
    # ä¸ºæœ¬æ¬¡åˆ—è¡¨å¤„ç†åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„ JS URL ç¼“å­˜
    processed_js_urls_cache: Set[str] = set()

    try:
        # å…ˆè¯»å–æ‰€æœ‰æœ‰æ•ˆ URL åˆ°åˆ—è¡¨ï¼Œä»¥ä¾¿è®¡ç®—æ€»æ•°å¹¶æ˜¾ç¤ºè¿›åº¦
        urls_to_process = list(read_urls_from_file(file_path))
        total_urls = len(urls_to_process)
        # ç§»é™¤æ‰¾åˆ° URL æ€»æ•°çš„æ‰“å° (ä¸ç¬¦åˆç¤ºä¾‹æ ¼å¼)
        # print(f"  å‘ç° {Colors.COUNT}{total_urls}{Colors.RESET} ä¸ª URL æ¡ç›®ã€‚")

        # éå† URL åˆ—è¡¨è¿›è¡Œå¤„ç†
        for i, url in enumerate(urls_to_process, 1):
            # ç§»é™¤æ‰“å°å½“å‰å¤„ç†è¿›åº¦ (ä¸ç¬¦åˆç¤ºä¾‹æ ¼å¼)
            # print(f"\n[{i}/{total_urls}] ", end="") # end="" é¿å…é¢å¤–æ¢è¡Œï¼Œè®©åç»­å¤„ç†å‡½æ•°æ‰“å°è‡ªå·±çš„èµ·å§‹ä¿¡æ¯
            log.info(f"[{i}/{total_urls}] Processing {list_type}: {url}") # è®°å½•åˆ°æ—¥å¿—
            try:
                # æ ¹æ®åˆ—è¡¨ç±»å‹è°ƒç”¨ä¸åŒçš„å¤„ç†å‡½æ•°
                if is_js_list:
                    # process_js_url å‡½æ•°å†…éƒ¨çš„æ‰“å°ä¹Ÿå·²ç»è¢«ç§»é™¤
                    # æ³¨æ„ï¼šè¿™é‡Œä¸æ‰“å° "å¼€å§‹åˆ†æ JS URL"ï¼Œå› ä¸ºè¿™æ˜¯åˆ—è¡¨é¡¹
                    # æå–ç»“æœæ‘˜è¦ä¼šåœ¨ process_js_content ä¸­æ‰“å°
                    process_js_url(url, output_file, processed_js_urls_cache)
                else:
                    # process_web_page å‡½æ•°å†…éƒ¨çš„æ‰“å°ä¹Ÿå·²ç»è¢«ç§»é™¤
                    # æ³¨æ„ï¼šè¿™é‡Œä¸æ‰“å° "å¼€å§‹åˆ†æç½‘é¡µ"ï¼Œå› ä¸ºè¿™æ˜¯åˆ—è¡¨é¡¹
                    # æå–ç»“æœæ‘˜è¦ä¼šåœ¨ process_js_content ä¸­æ‰“å°
                    process_web_page(url, output_file, processed_js_urls_cache)
                processed_count += 1 # æˆåŠŸå¤„ç†ï¼Œè®¡æ•°åŠ ä¸€
            except Exception as e:
                 # æ•è·å¤„ç†å•ä¸ª URL æ—¶æœªè¢«å†…éƒ¨å¤„ç†å‡½æ•°æ•è·çš„é¡¶å±‚å¼‚å¸¸ (ç†è®ºä¸Šå°‘è§)
                 log.error(f"å¤„ç†åˆ—è¡¨é¡¹ {i} ({url}) æ—¶å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}", exc_info=True)
                 # æ¢å¤å¤„ç†åˆ—è¡¨é¡¹å¤±è´¥æ‰“å°åˆ° stderr
                 print(f"\t{Colors.FAIL}âŒ å¤„ç†åˆ—è¡¨é¡¹ {i} ({url}) æ—¶å¤±è´¥: {e}{Colors.RESET}", file=sys.stderr)
                 utils.write_to_file(output_file, f"é”™è¯¯ï¼šå¤„ç†åˆ—è¡¨é¡¹ {i} ({url}) æ—¶å¤±è´¥: {e}\n\n")
                 error_count += 1 # å¤„ç†å¤±è´¥ï¼Œè®¡æ•°åŠ ä¸€

        # --- åˆ—è¡¨å¤„ç†å®Œæˆåçš„æ€»ç»“ä¿¡æ¯ ---
        if processed_count == 0 and error_count == 0 and total_urls == 0:
             # æ–‡ä»¶å­˜åœ¨ä½†ä¸ºç©ºæˆ–æ— æœ‰æ•ˆ URL çš„æƒ…å†µ
             if file_path.is_file() and file_path.stat().st_size == 0:
                 no_urls_msg = f"ä¿¡æ¯ï¼šURL åˆ—è¡¨æ–‡ä»¶ '{file_path}' ä¸ºç©ºã€‚"
             else:
                 # æ–‡ä»¶ä¸å­˜åœ¨æˆ–å­˜åœ¨ä½†æ— æœ‰æ•ˆ URL
                 no_urls_msg = f"ä¿¡æ¯ï¼šURL åˆ—è¡¨æ–‡ä»¶ '{file_path}' ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆ URL æˆ–æ–‡ä»¶ä¸å­˜åœ¨ã€‚"
             log.info(no_urls_msg)
             # æ¢å¤è­¦å‘Šæ‰“å°
             print(f"\t{Colors.WARNING}âš ï¸ {no_urls_msg}{Colors.RESET}")
             utils.write_to_file(output_file, no_urls_msg + "\n")
        else:
             # æ‰“å°å¤„ç†ç»“æœæ€»ç»“ - ç§»é™¤æ‰“å°ï¼Œåªè®°å½•æ—¥å¿— (ä¸ç¬¦åˆç¤ºä¾‹æ ¼å¼)
             summary_msg = f"{list_type} åˆ—è¡¨æ–‡ä»¶ {file_path} å¤„ç†å®Œæˆï¼Œå…±æˆåŠŸå¤„ç† {processed_count} ä¸ª URLï¼Œå¤±è´¥ {error_count} ä¸ªã€‚"
             log.info(summary_msg)
             # print(f"\n{Colors.SUCCESS}âœ… {summary_msg}{Colors.RESET}")
             utils.write_to_file(output_file, f"\n{summary_msg}\n")

    except (FileNotFoundError, IOError):
        # å¤„ç†æ–‡ä»¶è¯»å–é”™è¯¯ (å·²åœ¨ read_urls_from_file ä¸­è®°å½•æ—¥å¿—)
        error_msg = f"é”™è¯¯ï¼šæ— æ³•è¯»å– URL åˆ—è¡¨æ–‡ä»¶: {file_path}"
        log.error(error_msg)
        # æ¢å¤é”™è¯¯æ‰“å°åˆ° stderr
        print(f"{Colors.FAIL}âŒ {error_msg}{Colors.RESET}", file=sys.stderr)
        # å†æ¬¡å†™å…¥é”™è¯¯ä¿¡æ¯åˆ°è¾“å‡ºæ–‡ä»¶
        utils.write_to_file(output_file, error_msg + "\n\n")
    except Exception as e:
        # å¤„ç†è¯»å–æˆ–å¾ªç¯è¿‡ç¨‹ä¸­å…¶ä»–æ„å¤–é”™è¯¯
        error_msg = f"å¤„ç† URL åˆ—è¡¨æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}"
        log.error(error_msg, exc_info=True)
        # æ¢å¤é”™è¯¯æ‰“å°åˆ° stderr
        print(f"{Colors.FAIL}âŒ {error_msg}{Colors.RESET}", file=sys.stderr)
        utils.write_to_file(output_file, error_msg + "\n\n")

def process_web_page(page_url: str, output_file_path: Union[str, Path], processed_js_urls_cache: Set[str]) -> None:
    """
    å¤„ç†å•ä¸ªç½‘é¡µ URLï¼šä¸‹è½½ HTMLï¼Œæå–å¹¶åˆ†æå…¶ä¸­çš„ JSã€‚
    ä¿ç•™æ‰“å°ä¿¡æ¯ã€‚

    Args:
        page_url: ç½‘é¡µ URLã€‚
        output_file_path: ç»“æœè¾“å‡ºæ–‡ä»¶çš„è·¯å¾„ (å­—ç¬¦ä¸²æˆ– Path å¯¹è±¡)ã€‚
        processed_js_urls_cache: å·²å¤„ç† JS URL çš„ç¼“å­˜é›†åˆã€‚
    """
    log.info(f"å‡†å¤‡åˆ†æç½‘é¡µ: {page_url}")
    # æ¢å¤å¼€å§‹åˆ†æç½‘é¡µçš„æ¶ˆæ¯æ‰“å°ï¼Œä¿®æ”¹æ ¼å¼ä»¥åŒ¹é…ç¤ºä¾‹
    print(f"ğŸ”{Colors.INFO}å¼€å§‹åˆ†æç½‘é¡µ: {Colors.PATH}{page_url}{Colors.RESET}")

    # éªŒè¯ URL
    if not _is_valid_url(page_url):
        error_msg = f"é”™è¯¯ï¼šæä¾›çš„ç½‘é¡µ URL æ— æ•ˆæˆ–ä¸æ”¯æŒ: {page_url}"
        log.error(error_msg)
        # æ¢å¤æ— æ•ˆç½‘é¡µ URL æ‰“å°åˆ° stderr
        print(f"\t{Colors.FAIL}âŒ æ— æ•ˆç½‘é¡µ URL: {page_url}{Colors.RESET}", file=sys.stderr)
        utils.write_to_file(output_file_path, error_msg + "\n\n")
        return

    # å†™å…¥æ–‡ä»¶åˆ†éš”ç¬¦
    utils.write_to_file(output_file_path, f"## åˆ†æç½‘é¡µ: {page_url}\n" + "="*60 + "\n")
    # ä¸‹è½½ HTML å†…å®¹
    html_content = _fetch_content(page_url)

    if html_content is not None: # æ£€æŸ¥ä¸‹è½½æ˜¯å¦æˆåŠŸ
        if html_content: # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
            # è°ƒç”¨å‡½æ•°æå–å¹¶å¤„ç† HTML ä¸­çš„ JS
            # _extract_js_from_html å‡½æ•°å†…éƒ¨çš„æ‰“å°ä¹Ÿå·²ç»è¢«ç§»é™¤
            _extract_js_from_html(html_content, page_url, output_file_path, processed_js_urls_cache)
            # æ‰¾åˆ° JS çš„æ¶ˆæ¯åœ¨ _extract_js_from_html å†…éƒ¨æ‰“å° - ç°åœ¨ä¹Ÿç§»é™¤äº†
        else:
            # ç½‘é¡µå†…å®¹ä¸ºç©º
            log.warning(f"ç½‘é¡µè¿”å›ç©ºå†…å®¹: {page_url}")
            # æ¢å¤ç½‘é¡µè¿”å›ç©ºå†…å®¹è­¦å‘Šæ‰“å°
            print(f"\t{Colors.WARNING}âš ï¸ ç½‘é¡µè¿”å›ç©ºå†…å®¹: {page_url}{Colors.RESET}")
            utils.write_to_file(output_file_path, f"è­¦å‘Šï¼šç½‘é¡µè¿”å›ç©ºå†…å®¹: {page_url}\n\n")
    # else: ä¸‹è½½å¤±è´¥çš„é”™è¯¯å·²ç»åœ¨ _fetch_content ä¸­å¤„ç†å¹¶æ‰“å°
